#!/usr/bin/env python3
"""
NOTE: The characters after this line may have been generated by a language modeling algorithm.
Extract SMPL-X joint parameters from video as a time series.
Outputs the 55 SMPL-X joint rotations per frame with detection flags.
"""

import torch
import cv2
import numpy as np
import json
import pickle
from pathlib import Path
import argparse
from tqdm import tqdm


def extract_smplx_from_video_pymafx(video_path, output_path, device='cuda'):
    """
    Extract SMPL-X parameters from video using PyMAF-X.
    
    SMPL-X has 55 joints total:
    - 1 root (pelvis)
    - 21 body joints 
    - 30 hand joints (15 per hand)
    - 3 head/neck joints
    
    Each joint has 3D rotation (axis-angle), so 55 × 3 = 165 parameters for full pose.
    """
    try:
        # Try to import PyMAF-X (needs to be installed separately)
        from mafu.models import pymafx
        from mafu.core import constants, config
        from mafu.utils.demo_utils import (
            images_to_video, convert_crop_cam_to_orig_img
        )
        print("PyMAF-X loaded successfully")
        use_pymafx = True
    except ImportError:
        print("WARNING: PyMAF-X not installed. Using fallback method.")
        print("For best results, install PyMAF-X:")
        print("  git clone https://github.com/HongwenZhang/PyMAF-X.git")
        print("  cd PyMAF-X && pip install -r requirements.txt")
        use_pymafx = False
    
    # Open video
    cap = cv2.VideoCapture(str(video_path))
    if not cap.isOpened():
        raise ValueError(f"Could not open video: {video_path}")
    
    # Get video properties
    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = cap.get(cv2.CAP_PROP_FPS)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    print(f"Processing video: {video_path}")
    print(f"Resolution: {frame_width}x{frame_height}, FPS: {fps}, Frames: {total_frames}")
    
    # Initialize SMPL-X time series
    smplx_timeseries = {
        'metadata': {
            'video_path': str(video_path),
            'frame_width': frame_width,
            'frame_height': frame_height,
            'fps': fps,
            'total_frames': total_frames,
            'num_joints': 55,
            'joint_format': 'axis-angle',  # 3D rotation per joint
            'joint_names': get_smplx_joint_names()
        },
        'frames': []
    }
    
    if use_pymafx:
        # Use PyMAF-X for extraction
        smplx_timeseries = extract_with_pymafx(
            cap, smplx_timeseries, device, total_frames
        )
    else:
        # Use fallback method (4DHumans or FrankMocap)
        smplx_timeseries = extract_with_fallback(
            cap, smplx_timeseries, video_path, total_frames
        )
    
    cap.release()
    
    # Save to file
    output_path = Path(output_path)
    
    # Save as JSON (human-readable but large)
    json_path = output_path.with_suffix('.json')
    with open(json_path, 'w') as f:
        json.dump(smplx_timeseries, f, indent=2)
    print(f"\nSaved JSON to: {json_path}")
    
    # Save as pickle (compact)
    pkl_path = output_path.with_suffix('.pkl')
    with open(pkl_path, 'wb') as f:
        pickle.dump(smplx_timeseries, f)
    print(f"Saved pickle to: {pkl_path}")
    
    # Save as NPZ (easy to load in numpy/pytorch)
    save_as_npz(smplx_timeseries, output_path.with_suffix('.npz'))
    
    return smplx_timeseries


def get_smplx_joint_names():
    """
    Return the names of all 55 SMPL-X joints in order.
    """
    return [
        # Root (1)
        'pelvis',
        
        # Body (21)
        'left_hip', 'right_hip', 'spine1', 'left_knee', 'right_knee',
        'spine2', 'left_ankle', 'right_ankle', 'spine3', 'left_foot',
        'right_foot', 'neck', 'left_collar', 'right_collar', 'head',
        'left_shoulder', 'right_shoulder', 'left_elbow', 'right_elbow',
        'left_wrist', 'right_wrist',
        
        # Jaw (1)
        'jaw',
        
        # Left Eye (2)
        'left_eye_smplx', 'left_eye',
        
        # Right Eye (2) 
        'right_eye_smplx', 'right_eye',
        
        # Left Hand (15)
        'left_index1', 'left_index2', 'left_index3',
        'left_middle1', 'left_middle2', 'left_middle3',
        'left_pinky1', 'left_pinky2', 'left_pinky3',
        'left_ring1', 'left_ring2', 'left_ring3',
        'left_thumb1', 'left_thumb2', 'left_thumb3',
        
        # Right Hand (15)
        'right_index1', 'right_index2', 'right_index3',
        'right_middle1', 'right_middle2', 'right_middle3',
        'right_pinky1', 'right_pinky2', 'right_pinky3',
        'right_ring1', 'right_ring2', 'right_ring3',
        'right_thumb1', 'right_thumb2', 'right_thumb3',
    ]


def extract_with_fallback(cap, smplx_timeseries, video_path, total_frames):
    """
    Fallback extraction using available libraries.
    Tries 4DHumans first, then FrankMocap.
    """
    print("\nAttempting extraction with available methods...")
    
    # Try 4DHumans (HMR 2.0)
    try:
        from hmr2.models import HMR2
        from hmr2.utils import recursive_to
        from hmr2.datasets.utils import expand_to_aspect_ratio
        from hmr2.utils.renderer import Renderer
        
        print("Using 4DHumans (HMR 2.0)...")
        return extract_with_4dhumans(cap, smplx_timeseries, total_frames)
    except ImportError:
        print("4DHumans not available.")
    
    # Try FrankMocap
    try:
        from frankmocap.hand_modules.hand_mocap_api import HandMocap
        from frankmocap.bodymocap_api import BodyMocap
        
        print("Using FrankMocap...")
        return extract_with_frankmocap(cap, smplx_timeseries, total_frames)
    except ImportError:
        print("FrankMocap not available.")
    
    # If nothing available, create placeholder data
    print("\nWARNING: No SMPL-X extraction library available!")
    print("Generating placeholder data. Please install one of:")
    print("  1. PyMAF-X: https://github.com/HongwenZhang/PyMAF-X")
    print("  2. 4DHumans: https://github.com/shubham-goel/4D-Humans")
    print("  3. FrankMocap: https://github.com/facebookresearch/frankmocap")
    
    return create_placeholder_data(cap, smplx_timeseries, total_frames)


def extract_with_4dhumans(cap, smplx_timeseries, total_frames):
    """Extract using 4DHumans library."""
    from hmr2.models import HMR2, download_models, load_hmr2
    
    # Load model
    model, model_cfg = load_hmr2()
    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
    model = model.to(device)
    model.eval()
    
    frame_idx = 0
    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
    
    with torch.no_grad():
        pbar = tqdm(total=total_frames, desc="Extracting SMPL-X")
        
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break
            
            # Prepare image
            img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            img_tensor = torch.from_numpy(img).permute(2, 0, 1).float() / 255.0
            img_tensor = img_tensor.unsqueeze(0).to(device)
            
            # Run inference
            batch = {'img': img_tensor}
            output = model(batch)
            
            # Extract SMPL-X parameters
            pred_smplx = output['pred_smplx']
            
            # Get body pose (55 joints × 3 = 165 parameters)
            body_pose = pred_smplx['body_pose'][0].cpu().numpy()  # Shape: (55, 3)
            global_orient = pred_smplx['global_orient'][0].cpu().numpy()  # Shape: (3,)
            
            # Check if human was detected
            detection_confidence = output.get('detection_score', [1.0])[0]
            detected = detection_confidence > 0.3
            
            frame_data = {
                'frame_number': frame_idx,
                'timestamp': frame_idx / smplx_timeseries['metadata']['fps'],
                'detected': detected,
                'detection_confidence': float(detection_confidence),
                'global_orientation': global_orient.tolist(),  # Root orientation
                'joint_rotations': body_pose.tolist() if detected else None,  # 55 × 3
                'shape_params': pred_smplx['betas'][0].cpu().numpy().tolist() if detected else None,
            }
            
            smplx_timeseries['frames'].append(frame_data)
            frame_idx += 1
            pbar.update(1)
        
        pbar.close()
    
    return smplx_timeseries


def create_placeholder_data(cap, smplx_timeseries, total_frames):
    """
    Create placeholder data structure when no library is available.
    This shows the expected format.
    """
    frame_idx = 0
    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
    
    pbar = tqdm(total=total_frames, desc="Creating placeholder data")
    
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        
        frame_data = {
            'frame_number': frame_idx,
            'timestamp': frame_idx / smplx_timeseries['metadata']['fps'],
            'detected': False,  # Not detected (placeholder)
            'detection_confidence': 0.0,
            'global_orientation': None,  # [3] - root orientation
            'joint_rotations': None,  # [55, 3] - 55 joints, 3D axis-angle each
            'shape_params': None,  # [10] - body shape parameters
            'expression_params': None,  # [10] - facial expression
            'left_hand_pose': None,  # [15, 3] - left hand joint angles
            'right_hand_pose': None,  # [15, 3] - right hand joint angles
        }
        
        smplx_timeseries['frames'].append(frame_data)
        frame_idx += 1
        pbar.update(1)
    
    pbar.close()
    
    print("\n" + "="*60)
    print("PLACEHOLDER DATA GENERATED")
    print("="*60)
    print("This shows the expected output format, but contains no real data.")
    print("Install a library above to extract actual SMPL-X parameters.")
    print("="*60)
    
    return smplx_timeseries


def save_as_npz(smplx_timeseries, output_path):
    """
    Save SMPL-X timeseries as NPZ for easy loading in numpy/pytorch.
    """
    frames = smplx_timeseries['frames']
    n_frames = len(frames)
    
    # Prepare arrays
    detected = np.array([f['detected'] for f in frames], dtype=bool)
    confidences = np.array([f.get('detection_confidence', 0.0) for f in frames])
    
    # Joint rotations: (n_frames, 55, 3)
    joint_rotations = np.zeros((n_frames, 55, 3))
    for i, frame in enumerate(frames):
        if frame['joint_rotations'] is not None:
            joint_rotations[i] = np.array(frame['joint_rotations'])
        else:
            joint_rotations[i] = np.nan  # Mark as not detected
    
    # Global orientation: (n_frames, 3)
    global_orient = np.zeros((n_frames, 3))
    for i, frame in enumerate(frames):
        if frame['global_orientation'] is not None:
            global_orient[i] = np.array(frame['global_orientation'])
        else:
            global_orient[i] = np.nan
    
    # Shape parameters: (n_frames, 10)
    shape_params = np.zeros((n_frames, 10))
    for i, frame in enumerate(frames):
        if frame.get('shape_params') is not None:
            shape_params[i] = np.array(frame['shape_params'])
        else:
            shape_params[i] = np.nan
    
    # Save
    np.savez(
        output_path,
        detected=detected,
        confidences=confidences,
        joint_rotations=joint_rotations,  # (n_frames, 55, 3)
        global_orientation=global_orient,  # (n_frames, 3)
        shape_params=shape_params,  # (n_frames, 10)
        fps=smplx_timeseries['metadata']['fps'],
        joint_names=smplx_timeseries['metadata']['joint_names'],
    )
    
    print(f"Saved NPZ to: {output_path}")
    print(f"  Shape of joint_rotations: {joint_rotations.shape}")
    print(f"  Detected frames: {detected.sum()}/{n_frames}")


def load_npz_timeseries(npz_path):
    """
    Load SMPL-X timeseries from NPZ file.
    
    Returns:
        dict with keys: detected, confidences, joint_rotations, global_orientation, 
                       shape_params, fps, joint_names
    """
    data = np.load(npz_path, allow_pickle=True)
    return {
        'detected': data['detected'],
        'confidences': data['confidences'],
        'joint_rotations': data['joint_rotations'],  # (n_frames, 55, 3)
        'global_orientation': data['global_orientation'],
        'shape_params': data['shape_params'],
        'fps': float(data['fps']),
        'joint_names': data['joint_names'].tolist(),
    }


def main():
    parser = argparse.ArgumentParser(
        description='Extract SMPL-X joint parameters from video as time series'
    )
    parser.add_argument('video', type=str, help='Path to input video file')
    parser.add_argument('-o', '--output', type=str, help='Output file path (without extension)')
    parser.add_argument('--device', type=str, default='cuda', 
                       choices=['cuda', 'cpu'], help='Device to use')
    
    args = parser.parse_args()
    
    # Set default output path
    if args.output is None:
        video_path = Path(args.video)
        args.output = video_path.stem + '_smplx'
    
    # Check device availability
    if args.device == 'cuda' and not torch.cuda.is_available():
        print("CUDA not available, using CPU")
        args.device = 'cpu'
    
    # Extract SMPL-X parameters
    smplx_data = extract_smplx_from_video_pymafx(
        args.video,
        args.output,
        device=args.device
    )
    
    # Print summary
    frames = smplx_data['frames']
    detected_count = sum(1 for f in frames if f['detected'])
    
    print("\n=== Extraction Summary ===")
    print(f"Total frames: {len(frames)}")
    print(f"Detected frames: {detected_count}/{len(frames)} ({100*detected_count/len(frames):.1f}%)")
    print(f"SMPL-X joints: 55 (each with 3D axis-angle rotation)")
    print(f"\nOutput files:")
    print(f"  - JSON: {args.output}.json (human-readable)")
    print(f"  - PKL: {args.output}.pkl (Python pickle)")
    print(f"  - NPZ: {args.output}.npz (numpy arrays)")
    
    # Show example usage
    print("\n=== Example: Load and Use Data ===")
    print(f"""
import numpy as np

# Load the data
data = np.load('{args.output}.npz', allow_pickle=True)

# Get joint rotations for all frames
joint_rotations = data['joint_rotations']  # Shape: (n_frames, 55, 3)
detected = data['detected']  # Shape: (n_frames,) - boolean array

# Get rotations for frame 10
frame_10_rotations = joint_rotations[10]  # Shape: (55, 3)

# Check if frame 10 was detected
if detected[10]:
    print("Frame 10 detected!")
    print("Left wrist rotation:", frame_10_rotations[20])  # Joint index 20
else:
    print("Frame 10 not detected (all values are NaN)")

# Get only detected frames
detected_frames = joint_rotations[detected]  # Shape: (n_detected, 55, 3)
""")


if __name__ == '__main__':
    main()
